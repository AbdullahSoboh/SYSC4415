{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1CgjHR223wu"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emslaboratory/SYSC4415/blob/master/W2026/Assignments/A1/SYSC4415_W26_A1.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8n9xlHhV23ww"
      },
      "source": [
        "### Required Setup for local Running if you are not using Google Colab\n",
        "\n",
        "Install [Anaconda distribution] (https://docs.anaconda.com/anaconda/install/)\n",
        "\n",
        "If you don't have Python on your computer, you can use the [Anaconda Python distribution](http://continuum.io/downloads) to install most of the Python packages you need. Anaconda provides a simple double-click installer for your convenience.\n",
        "\n",
        "This notebook uses several Python packages that come standard with the Anaconda Python distribution. The primary libraries that we'll be using are:\n",
        "\n",
        "* **NumPy**: Provides a fast numerical array structure and helper functions.\n",
        "* **pandas**: Provides a DataFrame structure to store data in memory and work with it easily and efficiently.\n",
        "* **scikit-learn/sklearn**: The essential Machine Learning package in Python.\n",
        "* **matplotlib**: Basic plotting library in Python; most other Python plotting libraries are built on top of it.\n",
        "* **Seaborn**: Advanced statistical plotting library.\n",
        "* **waterqmark**: A Jupyter Notebook extension for printing timestamps, version numbers, and hardware information.\n",
        "\n",
        "To make sure you have all of the packages you need, install them with `conda`:\n",
        "\n",
        "```\n",
        "conda create -n SYSC4415_tutorials python=3.11\n",
        "conda activate SYSC4415_tutorials\n",
        "\n",
        "conda install jupyter\n",
        "conda install numpy pandas scikit-learn matplotlib seaborn graphviz statsmodels\n",
        "conda install -c conda-forge watermark\n",
        "\n",
        "```\n",
        "\n",
        "`conda` may ask you to update some of them if you don't have the most recent version. Allow it to do so.\n",
        "\n",
        "## NOTE about Signature in Google Colab:\n",
        "\n",
        "Use `!pip install watermark` in Google Colab if you have errors while signing your notebook. If you work locally and follow the instructions above in the correct order, it should be already installed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IrYmeXf23ww"
      },
      "source": [
        "## General Instructions:\n",
        "\n",
        "Please print out values when asked using Python's print() function with f-strings where possible.\n",
        "\n",
        "Submit your saved notebook with all the outputs to Brightspace, but make sure that it will produce correct outputs upon restarting and click \"runtime\" → \"run all\" with clean outputs. Ensure your notebook displays all answers when this is clicked.\n",
        "\n",
        "## Your Submission MUST contain your signature at the bottom.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "tZMxXaKR23wx"
      },
      "outputs": [],
      "source": [
        "# Name: Abdulllah Soboh\n",
        "# Student Number: 101220742"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "oATrs2VG23wx"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "import graphviz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wj460eLJ23wx"
      },
      "source": [
        "## Section 1: Gradients (4 marks)\n",
        "Hint: use attached PDF if you get lost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IJfv_wl23wx",
        "outputId": "00cdf3e4-1e96-471a-f935-9d1c7f621352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Partial Derivatives Formulas\n",
            "f(x,y,z) = e^(x^2) + y^y + e^(xy) + z*cos(x)\n",
            "df/dx = 2x*e^(x^2) + y*e^(xy) - z*sin(x)\n",
            "df/dy = y^y * (1 + ln(y)) + x*e^(xy)\n",
            "df/dz = cos(x)\n",
            "\n",
            "Evaluation at (0, 1, 1)\n",
            "Partial derivative for x (df/dx): 1.0\n",
            "Partial derivative for y (df/dy): 1.0\n",
            "Partial derivative for z (df/dz): 1.0\n",
            "Gradient: [1.0, 1.0, 1.0]\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Q1a (1 mark)\n",
        "- Manually derive and calculate the gradient of the function: f(x,y,z) = e^(x²) + y^y + e^(xy) + zcos(x) at point (0,1, 1)\n",
        "- Show each component of the gradient.\n",
        "\n",
        "Print your answer using print() function showing all three partial derivatives.\n",
        "\"\"\"\n",
        "\n",
        "# YOUR ANSWER HERE\n",
        "\n",
        "print(\"Partial Derivatives Formulas\")\n",
        "print(\"f(x,y,z) = e^(x^2) + y^y + e^(xy) + z*cos(x)\")\n",
        "print(\"df/dx = 2x*e^(x^2) + y*e^(xy) - z*sin(x)\")\n",
        "print(\"df/dy = y^y * (1 + ln(y)) + x*e^(xy)\")\n",
        "print(\"df/dz = cos(x)\")\n",
        "print(\"\\nEvaluation at (0, 1, 1)\")\n",
        "\n",
        "# Evaluating at x=0, y=1, z=1:\n",
        "# df/dx = 0 + 1 - 0 = 1\n",
        "# df/dy = 1 * (1 + 0) + 0 = 1\n",
        "# df/dz = 1\n",
        "\n",
        "print(f\"Partial derivative for x (df/dx): 1.0\")\n",
        "print(f\"Partial derivative for y (df/dy): 1.0\")\n",
        "print(f\"Partial derivative for z (df/dz): 1.0\")\n",
        "print(f\"Gradient: [1.0, 1.0, 1.0]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0_cUPhT23wx",
        "outputId": "3eb59912-36f9-4388-bc2d-53277e40ef81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Geometric Explanation:\n",
            "\n",
            "1. Component df/dx = 1:\n",
            "   Geometrically, this is the slope of the surface in the x-direction, with y and z held constant.\n",
            "   A value of 1 means that for a small unit step in the positive x-direction, \n",
            "   the function value increases by approximately 1 unit.\n",
            "\n",
            "2. Component df/dy = 1:\n",
            "   Similarly, this is the slope in the direction of the y-axis. \n",
            "   Moving in the positive y-direction causes the function to increase \n",
            "   at a rate of 1 unit per unit distance.\n",
            "\n",
            "3. Component df/dz = 1:\n",
            "   This is the slope in the direction of the z-axis. \n",
            "   Moving in the positive z-direction causes the function to increase \n",
            "   at a rate of 1 unit per unit distance.\n",
            "\n",
            "Conclusion:\n",
            "   The gradient vector (1, 1, 1) shows the direction where the function increases the fastest at the point (0, 1, 1).\n",
            "   Since all components are equal and positive, \n",
            "   the function is increasing equally fast in all three primary directions \n",
            "   (x, y, and z) at this specific location.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Q1b (1 mark)\n",
        "For each component of the gradient calculated in Q1a:\n",
        "- Explain what the value means geometrically\n",
        "- Provide a conclusion about each term and gradient in general\n",
        "\"\"\"\n",
        "\n",
        "# YOUR ANSWER HERE\n",
        "\n",
        "explanation = \"\"\"\n",
        "Geometric Explanation:\n",
        "\n",
        "1. Component df/dx = 1:\n",
        "   Geometrically, this is the slope of the surface in the x-direction, with y and z held constant.\n",
        "   A value of 1 means that for a small unit step in the positive x-direction,\n",
        "   the function value increases by approximately 1 unit.\n",
        "\n",
        "2. Component df/dy = 1:\n",
        "   Similarly, this is the slope in the direction of the y-axis.\n",
        "   Moving in the positive y-direction causes the function to increase\n",
        "   at a rate of 1 unit per unit distance.\n",
        "\n",
        "3. Component df/dz = 1:\n",
        "   This is the slope in the direction of the z-axis.\n",
        "   Moving in the positive z-direction causes the function to increase\n",
        "   at a rate of 1 unit per unit distance.\n",
        "\n",
        "Conclusion:\n",
        "   The gradient vector (1, 1, 1) shows the direction where the function increases the fastest at the point (0, 1, 1).\n",
        "   Since all components are equal and positive,\n",
        "   the function is increasing equally fast in all three primary directions\n",
        "   (x, y, and z) at this specific location.\n",
        "\"\"\"\n",
        "\n",
        "print(explanation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkFEYNj-23wy",
        "outputId": "0fe26aaa-72a1-416a-ee68-40f8e6558680"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function value at (0,1,1): 4.0\n",
            "\n",
            "Analytical Gradient (Math): [1. 1. 1.]\n",
            "Numerical Gradient (Code):  [1. 1. 1.]\n",
            "\n",
            "Difference (Should be very close to 0)\n",
            "x difference: 1.565336749109747e-11\n",
            "y difference: 5.0960125008714385e-11\n",
            "z difference: 1.565336749109747e-11\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Q1c (2 marks)\n",
        "Write a Python function to verify your gradient calculation numerically:\n",
        "1. Implement the function f(x,y,z)\n",
        "2. Calculate numerical approximations of partial derivatives using small perturbations\n",
        "3. Compare your analytical results from Q1a with numerical approximations\n",
        "4. Report the result of function evaluation at the point (0,1,1)\n",
        "\"\"\"\n",
        "\n",
        "# YOUR ANSWER HERE\n",
        "def f_func(x, y, z):\n",
        "    # f(x,y,z) = e^(x^2) + y^y + e^(xy) + z*cos(x)\n",
        "    return np.exp(x**2) + y**y + np.exp(x*y) + z * np.cos(x)\n",
        "\n",
        "def verify_gradient(x, y, z, h=1e-5):\n",
        "    # Calculate numerical partial derivatives using central difference\n",
        "\n",
        "    # Partial w.r.t x\n",
        "    df_dx_num = (f_func(x + h, y, z) - f_func(x - h, y, z)) / (2 * h)\n",
        "\n",
        "    # Partial w.r.t y\n",
        "    df_dy_num = (f_func(x, y + h, z) - f_func(x, y - h, z)) / (2 * h)\n",
        "\n",
        "    # Partial w.r.t z\n",
        "    df_dz_num = (f_func(x, y, z + h) - f_func(x, y, z - h)) / (2 * h)\n",
        "\n",
        "    return np.array([df_dx_num, df_dy_num, df_dz_num])\n",
        "\n",
        "# Defined point\n",
        "x_pt, y_pt, z_pt = 0, 1, 1\n",
        "\n",
        "# Get numerical results\n",
        "numerical_grad = verify_gradient(x_pt, y_pt, z_pt)\n",
        "function_value = f_func(x_pt, y_pt, z_pt)\n",
        "analytical_grad = np.array([1.0, 1.0, 1.0])\n",
        "\n",
        "# Print results simply\n",
        "print(\"Function value at (0,1,1):\", function_value)\n",
        "print(\"\\nAnalytical Gradient (Math):\", analytical_grad)\n",
        "print(\"Numerical Gradient (Code): \", numerical_grad)\n",
        "\n",
        "print(\"\\nDifference (Should be very close to 0)\")\n",
        "print(\"x difference:\", abs(analytical_grad[0] - numerical_grad[0]))\n",
        "print(\"y difference:\", abs(analytical_grad[1] - numerical_grad[1]))\n",
        "print(\"z difference:\", abs(analytical_grad[2] - numerical_grad[2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibaVMOfz23wy"
      },
      "source": [
        "## Section 2: Data Analysis (8 marks)\n",
        "\n",
        "This section uses the Palmer Penguins dataset, which contains measurements from three penguin species.\n",
        "The dataset includes physical measurements like bill length, bill depth, flipper length, and body mass. We are building a penguin classifier. First we need to assess out data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gx-ZPdnA23wy",
        "outputId": "dbd62c28-8824-4525-e581-4f8b22130136"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows\n",
            "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
            "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
            "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
            "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
            "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
            "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
            "\n",
            "   body_mass_g     sex  \n",
            "0       3750.0    Male  \n",
            "1       3800.0  Female  \n",
            "2       3250.0  Female  \n",
            "3          NaN     NaN  \n",
            "4       3450.0  Female  \n",
            "\n",
            "Numerical Features: ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n",
            "\n",
            "Statistics Table\n",
            "       bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g\n",
            "count      342.000000     342.000000         342.000000   342.000000\n",
            "mean        43.921930      17.151170         200.915205  4201.754386\n",
            "std          5.459584       1.974793          14.061714   801.954536\n",
            "min         32.100000      13.100000         172.000000  2700.000000\n",
            "25%         39.225000      15.600000         190.000000  3550.000000\n",
            "50%         44.450000      17.300000         197.000000  4050.000000\n",
            "75%         48.500000      18.700000         213.000000  4750.000000\n",
            "max         59.600000      21.500000         231.000000  6300.000000\n",
            "\n",
            "Missing Values Before Cleaning\n",
            "species               0\n",
            "island                0\n",
            "bill_length_mm        2\n",
            "bill_depth_mm         2\n",
            "flipper_length_mm     2\n",
            "body_mass_g           2\n",
            "sex                  11\n",
            "dtype: int64\n",
            "\n",
            "Saved 11 rows with missing 'sex' for later.\n",
            "Original dataset size: (344, 7)\n",
            "Clean dataset size: (333, 7)\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Q2a (1 mark)\n",
        "✅ Load the Palmer Penguins dataset using Seaborn's load_dataset (provided)\n",
        "- Show that it contains valid data\n",
        "- Create variables for numerical features and labels\n",
        "- Perform basic statistical analysis by printing the general statistics table as in Tutorials.\n",
        "- Find missing values and drop records with missing values for any feature\n",
        "- Save entries with missing values for \"sex\" in a separate variable, we'll use it later.\n",
        "\"\"\"\n",
        "\n",
        "# Load data\n",
        "penguins = sb.load_dataset(\"penguins\")\n",
        "\n",
        "# YOUR ANSWER HERE\n",
        "\n",
        "# 1. Show it contains valid data\n",
        "print(\"First 5 rows\")\n",
        "print(penguins.head())\n",
        "\n",
        "# 2. Create variables\n",
        "# We select columns that are numbers (float/int) for features\n",
        "numerical_features = penguins.select_dtypes(include=[np.number]).columns.tolist()\n",
        "label_column = 'species'\n",
        "print(f\"\\nNumerical Features: {numerical_features}\")\n",
        "\n",
        "# 3. Basic Stats\n",
        "print(\"\\nStatistics Table\")\n",
        "print(penguins.describe())\n",
        "\n",
        "# 4. Find & Handle Missing Values\n",
        "print(\"\\nMissing Values Before Cleaning\")\n",
        "print(penguins.isnull().sum())\n",
        "\n",
        "# Save rows where ONLY 'sex' is missing (for Section 4 later)\n",
        "# We make a copy so it doesn't get affected by later changes\n",
        "missing_sex_data = penguins[penguins['sex'].isnull()].copy()\n",
        "print(f\"\\nSaved {len(missing_sex_data)} rows with missing 'sex' for later.\")\n",
        "\n",
        "# Drop rows with ANY missing data from our working set\n",
        "clean_penguins = penguins.dropna()\n",
        "\n",
        "print(f\"Original dataset size: {penguins.shape}\")\n",
        "print(f\"Clean dataset size: {clean_penguins.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "TZ3wh3x623wy",
        "outputId": "2b01326b-69f5-4fd3-a1cd-1ec370257892"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nQ2b (2 marks)\\nCreate visualizations showing:\\n- Create scatterplot matrix for visual assessment of data\\n- Identify one feature with outliers and show distribution values for two classes (2 histograms).\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "\"\"\"\n",
        "Q2b (2 marks)\n",
        "Create visualizations showing:\n",
        "- Create scatterplot matrix for visual assessment of data\n",
        "- Identify one feature with outliers and show distribution values for two classes (2 histograms).\n",
        "\"\"\"\n",
        "\n",
        "# YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_k6vjBN023wy",
        "outputId": "19b8cfce-eaf3-467f-eabd-44984d6bc78c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nQ2c (1 mark)\\nAnalyze class distribution and discuss implications for model training:\\n- Calculate and visualize class proportions\\n- Identify any class imbalance\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "\"\"\"\n",
        "Q2c (1 mark)\n",
        "Analyze class distribution and discuss implications for model training:\n",
        "- Calculate and visualize class proportions\n",
        "- Identify any class imbalance\n",
        "\"\"\"\n",
        "\n",
        "# YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFfZOhnZ23wy"
      },
      "source": [
        "## Section 3: Model Development (8 marks)\n",
        "After polishing thedata, let's make our classification model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "MlmkjlAd23wy",
        "outputId": "280cd874-e077-49f3-ad7d-578a28357667"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nQ3a (2 marks)\\nPreprocess the data:\\n- Use the clean dataset from Q2a (with missing values removed)\\n- Split into training (80%) and test (20%) sets using random_state=42\\n- Print first 5 rows of training data with their species labels\\n- Print shapes of both datasets\\n- Show number of samples per species in each split\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "\"\"\"\n",
        "Q3a (2 marks)\n",
        "Preprocess the data:\n",
        "- Use the clean dataset from Q2a (with missing values removed)\n",
        "- Split into training (80%) and test (20%) sets using random_state=42\n",
        "- Print first 5 rows of training data with their species labels\n",
        "- Print shapes of both datasets\n",
        "- Show number of samples per species in each split\n",
        "\"\"\"\n",
        "\n",
        "# YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "ikqZqzdq23wy"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Q3b (3 marks)\n",
        "Train and evaluate a Decision Tree:\n",
        "1. Create a Decision Tree with default parameters (random_state=42)\n",
        "2. Evaluate the model:\n",
        "   - Fit on training data (numerical features only)\n",
        "   - Print training and test accuracy score for this tree\n",
        "   - Perform 10-fold cross-validation\n",
        "   - Print mean and std of cross-validation scores and build cv_scores histogram.\n",
        "   - What does the histogram show?\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# YOUR ANSWER HERE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "R9nml97i23wz"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Q3c (3 marks)\n",
        "Analyze the best model from grid search:\n",
        "- Initialize parameter_grid, cross_validation using StratifiedKFold\n",
        "- Identify the best parameters for the tree and show the grid heatmap (don't forget labels)\n",
        "- Plot the best tree structure using graphviz, use max_depth=2 (for better display)\n",
        "\n",
        "Note: when using export_graphviz set out_file=None and use display(graph) function call, where\n",
        "graph is your variable instantiated with Source(dot_data)\n",
        "Export_graphviz Documentation: https://scikit-learn.org/1.5/modules/generated/sklearn.tree.export_graphviz.html\n",
        "\"\"\"\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import graphviz\n",
        "from sklearn.tree import export_graphviz\n",
        "from graphviz import Source\n",
        "\n",
        "# YOUR ANSWER HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImIHX7Rg23wz"
      },
      "source": [
        "## Section 4: Missing_Sex Prediction (4 marks)\n",
        "In this part of the assignment, we are building a model to infer the missing values from the original dataset to fix the broken records.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "Ev99cd3523wz"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Q4a (2 marks)\n",
        "Prepare data for sex prediction:\n",
        "- Use the clean dataset (no missing values) from Section 2\n",
        "- Convert species to numeric values.\n",
        "\n",
        "Note: Unlike the example in the tutorial, we will use a more straightforward method, LabelEncoder().\n",
        "\n",
        "For this task, you just need to instantiate it, use the fit_transform method on the \"species\" column,\n",
        "and reassign or add the column.\n",
        "See documentation for details:\n",
        "https://scikit-learn.org/dev/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
        "\n",
        "- Create new feature/label split using \"sex\" as target\n",
        "- Scale features using StandardScaler().fit_transform(features) as in Tutorial\n",
        "See documentation: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
        "\n",
        "- Split data into training (80%) and test (20%) sets\n",
        "- Train these classifiers:\n",
        "  * Logistic Regression (solver='lbfgs')\n",
        "  * Decision Tree (max_depth=3)\n",
        "  * KNN (n_neighbors=5)\n",
        "  * SVM (kernel=\"linear\", C=0.025)\n",
        "- Compare models using (Providing values for each would be enough):\n",
        "  * Training and test accuracy\n",
        "  * 10-fold cross-validation scores\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Prepare features including species as numeric\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# YOUR ANSWER HERE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "TiCwAGkL23wz",
        "outputId": "72b639fd-ac60-45c8-e9a4-f59c72d76479"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nQ4b (2 marks)\\nUse best model to predict missing sex:\\n- Make sure to create new variable for subset to work with and copy your variable with missing records into it,\\nusing new_var = your_variable.copy().\\n- Print records with missing sex values from section 2.\\n- Remove records that have missing values other than sex using dropna: df.dropna(subset=['column_name'],inplace=True).\\n- Scale features using StandardScaler().fit_transform(features) as in Q3\\n- Create new features/labels variables for the new dataset. \\n\\n- Select best classifier based on test performance from Q4a\\n\\n- For each record in missing_sex dataset, using best_model.predict(features) and best_model.predict_proba(features)\\n- Add missing values to the clean dataset and make sure there are no missing values.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "\"\"\"\n",
        "Q4b (2 marks)\n",
        "Use best model to predict missing sex:\n",
        "- Make sure to create new variable for subset to work with and copy your variable with missing records into it,\n",
        "using new_var = your_variable.copy().\n",
        "- Print records with missing sex values from section 2.\n",
        "- Remove records that have missing values other than sex using dropna: df.dropna(subset=['column_name'],inplace=True).\n",
        "- Scale features using StandardScaler().fit_transform(features) as in Q3\n",
        "- Create new features/labels variables for the new dataset.\n",
        "\n",
        "- Select best classifier based on test performance from Q4a\n",
        "\n",
        "- For each record in missing_sex dataset, using best_model.predict(features) and best_model.predict_proba(features)\n",
        "- Add missing values to the clean dataset and make sure there are no missing values.\n",
        "\"\"\"\n",
        "\n",
        "# YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP_aL4zY23wz"
      },
      "source": [
        "#### Congratulations! What you just did is called **model-based multiple imputation**. It is one of the methods used to treat missing data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-pFRRH923wz"
      },
      "source": [
        "## Signature:\n",
        "Don't forget to insert your name and student number and execute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIxJmPbZ23wz",
        "outputId": "dcd51829-a342-4c3e-b5b3-581f7f254743"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: watermark in /usr/local/lib/python3.12/dist-packages (2.6.0)\n",
            "Requirement already satisfied: ipython>=6.0 in /usr/local/lib/python3.12/dist-packages (from watermark) (7.34.0)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.12/dist-packages (from watermark) (8.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from watermark) (75.2.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata>=1.4->watermark) (3.23.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.0->watermark) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=6.0->watermark) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=6.0->watermark) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.0->watermark) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.0->watermark) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=6.0->watermark) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=6.0->watermark) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython>=6.0->watermark) (0.2.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.0->watermark) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=6.0->watermark) (0.8.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=6.0->watermark) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.0->watermark) (0.5.0)\n",
            "The watermark extension is already loaded. To reload it, use:\n",
            "  %reload_ext watermark\n",
            "Author: Abdullah Soboh, #101220742 -nmv --packages numpy,pandas,sklearn,matplotlib,seaborn,graphviz\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Provide your Signarure:\n",
        "!pip install watermark\n",
        "%load_ext watermark\n",
        "%watermark -a 'Abdullah Soboh, #101220742 -nmv --packages numpy,pandas,sklearn,matplotlib,seaborn,graphviz'"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}